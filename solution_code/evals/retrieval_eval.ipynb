{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_with_semantic_vectors_path = \"../data/dense_embedddings_with_index.parquet\"\n",
    "data_with_tfidf_vectors_path = \"../data/sparse_embeddings_with_index.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_df = pd.read_parquet(data_with_semantic_vectors_path)\n",
    "tfidf_df = pd.read_pickle(data_with_tfidf_vectors_path)\n",
    "df_combined = pd.concat([semantic_df, tfidf_df], axis=1)\n",
    "df_combined[\"Abbreviation\"] = df_combined.index.str.split(\"/\").str[0].str.split(\"_\").str[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Question</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>embedding_context</th>\n",
       "      <th>embedding_question</th>\n",
       "      <th>Context_TFIDF_Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Single_STT/2013/page_54.pdf-4</th>\n",
       "      <td>Pre-Text:[\"shareholder return performance pres...</td>\n",
       "      <td>how much higher are the returns of the s&amp;p 500...</td>\n",
       "      <td>what is the fraction change of the investment ...</td>\n",
       "      <td>[0.016610916703939438, -0.0038285385817289352,...</td>\n",
       "      <td>[-0.014002669602632523, -0.0030809114687144756...</td>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single_STT/2011/page_94.pdf-3</th>\n",
       "      <td>Pre-Text:['we maintain an effective universal ...</td>\n",
       "      <td>what was the percent change in the value of co...</td>\n",
       "      <td>what was the value of commercial paper outstan...</td>\n",
       "      <td>[-0.013737378641963005, -0.01657671481370926, ...</td>\n",
       "      <td>[-0.0014009354636073112, -0.013579033315181732...</td>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single_STT/2014/page_69.pdf-2</th>\n",
       "      <td>Pre-Text:['management 2019s discussion and ana...</td>\n",
       "      <td>what is the percentage change in the average t...</td>\n",
       "      <td>what was the value of average short term advan...</td>\n",
       "      <td>[-0.008708413690328598, -0.007725966162979603,...</td>\n",
       "      <td>[-0.028621919453144073, 0.022226709872484207, ...</td>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single_STT/2009/page_122.pdf-4</th>\n",
       "      <td>Pre-Text:['note 10 .', 'commitments and contin...</td>\n",
       "      <td>what is the percent change in asset purchase a...</td>\n",
       "      <td>what was the total in asset purchase agreement...</td>\n",
       "      <td>[-0.007598159369081259, -0.0395529605448246, -...</td>\n",
       "      <td>[-0.020172208547592163, 0.010079036466777325, ...</td>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single_STT/2013/page_175.pdf-2</th>\n",
       "      <td>Pre-Text:['state street corporation notes to c...</td>\n",
       "      <td>what is the percentage change in the balance o...</td>\n",
       "      <td>what was the total in asset purchase agreement...</td>\n",
       "      <td>[-0.0009236071491613984, -0.027679165825247765...</td>\n",
       "      <td>[-0.02635018341243267, 0.01037721149623394, -0...</td>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single_AMAT/2012/page_37.pdf-2</th>\n",
       "      <td>Pre-Text:['performance graph the performance g...</td>\n",
       "      <td>for how many common stock shares did the compa...</td>\n",
       "      <td>what was the product of the dividend paid per ...</td>\n",
       "      <td>[-0.0008334789890795946, -0.01523605827242136,...</td>\n",
       "      <td>[-0.017676647752523422, -0.008252725005149841,...</td>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single_AMAT/2014/page_37.pdf-2</th>\n",
       "      <td>Pre-Text:['performance graph the performance g...</td>\n",
       "      <td>how many shares received dividends during 2014...</td>\n",
       "      <td>what is the yearly dividend per share in 2014?...</td>\n",
       "      <td>[-0.0010122329695150256, -0.015447970479726791...</td>\n",
       "      <td>[-0.018255062401294708, 0.018669361248612404, ...</td>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Single_AMAT/2015/page_14.pdf-2</th>\n",
       "      <td>Pre-Text:['backlog applied manufactures system...</td>\n",
       "      <td>what is the growth rate in the segment of disp...</td>\n",
       "      <td>what was the display value in 2015?\\n-what was...</td>\n",
       "      <td>[-0.003818386932834983, 0.015724772587418556, ...</td>\n",
       "      <td>[-0.010050210170447826, 0.015472985804080963, ...</td>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Double_AMAT/2015/page_33.pdf</th>\n",
       "      <td>Pre-Text:['performance graph the performance g...</td>\n",
       "      <td>what is the yearly rate of return of s&amp;p500 if...</td>\n",
       "      <td>what is the net change in value of an investme...</td>\n",
       "      <td>[-0.005452048033475876, -0.012531572952866554,...</td>\n",
       "      <td>[-0.03288188576698303, -0.02652997523546219, -...</td>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Double_AMAT/2018/page_31.pdf</th>\n",
       "      <td>Pre-Text:['item 2 : properties information con...</td>\n",
       "      <td>what portion of total company used area is com...</td>\n",
       "      <td>what portion of the total area the company use...</td>\n",
       "      <td>[0.012366747483611107, 0.011582227423787117, -...</td>\n",
       "      <td>[0.0017673247493803501, -0.012965526431798935,...</td>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1588 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          Context  \\\n",
       "Single_STT/2013/page_54.pdf-4   Pre-Text:[\"shareholder return performance pres...   \n",
       "Single_STT/2011/page_94.pdf-3   Pre-Text:['we maintain an effective universal ...   \n",
       "Single_STT/2014/page_69.pdf-2   Pre-Text:['management 2019s discussion and ana...   \n",
       "Single_STT/2009/page_122.pdf-4  Pre-Text:['note 10 .', 'commitments and contin...   \n",
       "Single_STT/2013/page_175.pdf-2  Pre-Text:['state street corporation notes to c...   \n",
       "...                                                                           ...   \n",
       "Single_AMAT/2012/page_37.pdf-2  Pre-Text:['performance graph the performance g...   \n",
       "Single_AMAT/2014/page_37.pdf-2  Pre-Text:['performance graph the performance g...   \n",
       "Single_AMAT/2015/page_14.pdf-2  Pre-Text:['backlog applied manufactures system...   \n",
       "Double_AMAT/2015/page_33.pdf    Pre-Text:['performance graph the performance g...   \n",
       "Double_AMAT/2018/page_31.pdf    Pre-Text:['item 2 : properties information con...   \n",
       "\n",
       "                                                                         Question  \\\n",
       "Single_STT/2013/page_54.pdf-4   how much higher are the returns of the s&p 500...   \n",
       "Single_STT/2011/page_94.pdf-3   what was the percent change in the value of co...   \n",
       "Single_STT/2014/page_69.pdf-2   what is the percentage change in the average t...   \n",
       "Single_STT/2009/page_122.pdf-4  what is the percent change in asset purchase a...   \n",
       "Single_STT/2013/page_175.pdf-2  what is the percentage change in the balance o...   \n",
       "...                                                                           ...   \n",
       "Single_AMAT/2012/page_37.pdf-2  for how many common stock shares did the compa...   \n",
       "Single_AMAT/2014/page_37.pdf-2  how many shares received dividends during 2014...   \n",
       "Single_AMAT/2015/page_14.pdf-2  what is the growth rate in the segment of disp...   \n",
       "Double_AMAT/2015/page_33.pdf    what is the yearly rate of return of s&p500 if...   \n",
       "Double_AMAT/2018/page_31.pdf    what portion of total company used area is com...   \n",
       "\n",
       "                                                                         Dialogue  \\\n",
       "Single_STT/2013/page_54.pdf-4   what is the fraction change of the investment ...   \n",
       "Single_STT/2011/page_94.pdf-3   what was the value of commercial paper outstan...   \n",
       "Single_STT/2014/page_69.pdf-2   what was the value of average short term advan...   \n",
       "Single_STT/2009/page_122.pdf-4  what was the total in asset purchase agreement...   \n",
       "Single_STT/2013/page_175.pdf-2  what was the total in asset purchase agreement...   \n",
       "...                                                                           ...   \n",
       "Single_AMAT/2012/page_37.pdf-2  what was the product of the dividend paid per ...   \n",
       "Single_AMAT/2014/page_37.pdf-2  what is the yearly dividend per share in 2014?...   \n",
       "Single_AMAT/2015/page_14.pdf-2  what was the display value in 2015?\\n-what was...   \n",
       "Double_AMAT/2015/page_33.pdf    what is the net change in value of an investme...   \n",
       "Double_AMAT/2018/page_31.pdf    what portion of the total area the company use...   \n",
       "\n",
       "                                                                embedding_context  \\\n",
       "Single_STT/2013/page_54.pdf-4   [0.016610916703939438, -0.0038285385817289352,...   \n",
       "Single_STT/2011/page_94.pdf-3   [-0.013737378641963005, -0.01657671481370926, ...   \n",
       "Single_STT/2014/page_69.pdf-2   [-0.008708413690328598, -0.007725966162979603,...   \n",
       "Single_STT/2009/page_122.pdf-4  [-0.007598159369081259, -0.0395529605448246, -...   \n",
       "Single_STT/2013/page_175.pdf-2  [-0.0009236071491613984, -0.027679165825247765...   \n",
       "...                                                                           ...   \n",
       "Single_AMAT/2012/page_37.pdf-2  [-0.0008334789890795946, -0.01523605827242136,...   \n",
       "Single_AMAT/2014/page_37.pdf-2  [-0.0010122329695150256, -0.015447970479726791...   \n",
       "Single_AMAT/2015/page_14.pdf-2  [-0.003818386932834983, 0.015724772587418556, ...   \n",
       "Double_AMAT/2015/page_33.pdf    [-0.005452048033475876, -0.012531572952866554,...   \n",
       "Double_AMAT/2018/page_31.pdf    [0.012366747483611107, 0.011582227423787117, -...   \n",
       "\n",
       "                                                               embedding_question  \\\n",
       "Single_STT/2013/page_54.pdf-4   [-0.014002669602632523, -0.0030809114687144756...   \n",
       "Single_STT/2011/page_94.pdf-3   [-0.0014009354636073112, -0.013579033315181732...   \n",
       "Single_STT/2014/page_69.pdf-2   [-0.028621919453144073, 0.022226709872484207, ...   \n",
       "Single_STT/2009/page_122.pdf-4  [-0.020172208547592163, 0.010079036466777325, ...   \n",
       "Single_STT/2013/page_175.pdf-2  [-0.02635018341243267, 0.01037721149623394, -0...   \n",
       "...                                                                           ...   \n",
       "Single_AMAT/2012/page_37.pdf-2  [-0.017676647752523422, -0.008252725005149841,...   \n",
       "Single_AMAT/2014/page_37.pdf-2  [-0.018255062401294708, 0.018669361248612404, ...   \n",
       "Single_AMAT/2015/page_14.pdf-2  [-0.010050210170447826, 0.015472985804080963, ...   \n",
       "Double_AMAT/2015/page_33.pdf    [-0.03288188576698303, -0.02652997523546219, -...   \n",
       "Double_AMAT/2018/page_31.pdf    [0.0017673247493803501, -0.012965526431798935,...   \n",
       "\n",
       "                                                             Context_TFIDF_Vector  \n",
       "Single_STT/2013/page_54.pdf-4   <Compressed Sparse Row sparse matrix of dtype ...  \n",
       "Single_STT/2011/page_94.pdf-3   <Compressed Sparse Row sparse matrix of dtype ...  \n",
       "Single_STT/2014/page_69.pdf-2   <Compressed Sparse Row sparse matrix of dtype ...  \n",
       "Single_STT/2009/page_122.pdf-4  <Compressed Sparse Row sparse matrix of dtype ...  \n",
       "Single_STT/2013/page_175.pdf-2  <Compressed Sparse Row sparse matrix of dtype ...  \n",
       "...                                                                           ...  \n",
       "Single_AMAT/2012/page_37.pdf-2  <Compressed Sparse Row sparse matrix of dtype ...  \n",
       "Single_AMAT/2014/page_37.pdf-2  <Compressed Sparse Row sparse matrix of dtype ...  \n",
       "Single_AMAT/2015/page_14.pdf-2  <Compressed Sparse Row sparse matrix of dtype ...  \n",
       "Double_AMAT/2015/page_33.pdf    <Compressed Sparse Row sparse matrix of dtype ...  \n",
       "Double_AMAT/2018/page_31.pdf    <Compressed Sparse Row sparse matrix of dtype ...  \n",
       "\n",
       "[1588 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall with only Contextual Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Recall@1': 0.2128463476070529, 'Recall@3': 0.3677581863979849, 'Recall@5': 0.44584382871536526, 'Recall@10': 0.5516372795969773, 'Recall@20': 0.6492443324937027, 'Recall@40': 0.75}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample DataFrame (use your actual DataFrame)\n",
    "df = df_combined  # Your DataFrame\n",
    "\n",
    "# Convert embedding columns to NumPy arrays\n",
    "context_embeddings = np.vstack(df[\"embedding_context\"].values)   # Shape: (num_contexts, embedding_dim)\n",
    "question_embeddings = np.vstack(df[\"embedding_question\"].values) # Shape: (num_questions, embedding_dim)\n",
    "\n",
    "# Compute cosine similarity (each row in question_embeddings compared to all context embeddings)\n",
    "similarity_matrix = cosine_similarity(question_embeddings, context_embeddings)  # Shape: (num_questions, num_contexts)\n",
    "\n",
    "# Function to compute recall@K\n",
    "def compute_recall_at_k(similarity_matrix, k):\n",
    "    num_questions = similarity_matrix.shape[0]\n",
    "    correct_matches = 0\n",
    "    \n",
    "    for i in range(num_questions):\n",
    "        # Get indices of top K most similar context embeddings for question i\n",
    "        top_k_indices = np.argsort(similarity_matrix[i])[::-1][:k]  # Sort in descending order\n",
    "        \n",
    "        # Check if the correct context (same row in DataFrame) is in the top K\n",
    "        if i in top_k_indices:\n",
    "            correct_matches += 1\n",
    "\n",
    "    recall_at_k = correct_matches / num_questions\n",
    "    return recall_at_k\n",
    "\n",
    "# Evaluate recall for different values of K\n",
    "k_values = [1, 3, 5, 10, 20, 40]\n",
    "recall_scores = {f\"Recall@{k}\": compute_recall_at_k(similarity_matrix, k) for k in k_values}\n",
    "\n",
    "# Print recall scores\n",
    "print(recall_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall with TD-IDF Vectors only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Search Recall Scores: {'Recall@1': 0.24181360201511334, 'Recall@3': 0.3973551637279597, 'Recall@5': 0.47858942065491183, 'Recall@10': 0.5976070528967254, 'Recall@20': 0.7052896725440806, 'Recall@40': 0.8047858942065491}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample DataFrame (Use your actual DataFrame)\n",
    "df = df_combined  # Your dataset with 'Context' and 'QuestionsList'\n",
    "\n",
    "# Step 1: Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Step 2: Fit the TF-IDF vectorizer on the Contexts only (Do not train on questions)\n",
    "vectorizer.fit(df[\"Context\"].tolist())\n",
    "\n",
    "# Step 3: Transform the contexts and questions (note that questions are transformed using the pre-fitted vectorizer)\n",
    "context_tfidf = vectorizer.transform(df[\"Context\"].tolist())  # Transform the contexts\n",
    "question_tfidf = vectorizer.transform(df[\"Question\"].tolist())  # Transform the questions\n",
    "\n",
    "# Step 4: Compute cosine similarity (Lexical similarity between questions and contexts)\n",
    "lexical_similarity_matrix = cosine_similarity(question_tfidf, context_tfidf)\n",
    "\n",
    "# Step 5: Function to compute recall@K for lexical search\n",
    "def compute_recall_at_k_lexical(similarity_matrix, k):\n",
    "    num_questions = similarity_matrix.shape[0]\n",
    "    correct_matches = 0\n",
    "\n",
    "    for i in range(num_questions):\n",
    "        # Get indices of top K most similar contexts for question i\n",
    "        top_k_indices = np.argsort(similarity_matrix[i])[::-1][:k]\n",
    "\n",
    "        # Check if the correct context is in the top K\n",
    "        if i in top_k_indices:\n",
    "            correct_matches += 1\n",
    "\n",
    "    recall_at_k = correct_matches / num_questions\n",
    "    return recall_at_k\n",
    "\n",
    "# Step 6: Evaluate Recall@K for lexical search (for different values of k)\n",
    "k_values = [1, 3, 5, 10, 20, 40]\n",
    "lexical_recall_scores = {f\"Recall@{k}\": compute_recall_at_k_lexical(lexical_similarity_matrix, k) for k in k_values}\n",
    "\n",
    "# Step 7: Print lexical recall scores\n",
    "print(\"Lexical Search Recall Scores:\", lexical_recall_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Search Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Lexical + Embedding Search Recall Scores: {'Recall@1': 0.28463476070528965, 'Recall@3': 0.464735516372796, 'Recall@5': 0.5434508816120907, 'Recall@10': 0.6511335012594458, 'Recall@20': 0.7651133501259446, 'Recall@40': 0.8589420654911839}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample DataFrame (Use your actual DataFrame)\n",
    "df = df_combined  # Your dataset with 'Context', 'QuestionsList', 'embedding_small_context', 'embedding_small_question'\n",
    "\n",
    "# Step 1: Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Step 2: Fit the TF-IDF vectorizer on the Contexts only (Do not train on questions)\n",
    "vectorizer.fit(df[\"Context\"].tolist())\n",
    "\n",
    "# Step 3: Transform the contexts and questions (note that questions are transformed using the pre-fitted vectorizer)\n",
    "context_tfidf = vectorizer.transform(df[\"Context\"].tolist())  # Transform the contexts\n",
    "question_tfidf = vectorizer.transform(df[\"Question\"].tolist())  # Transform the questions\n",
    "\n",
    "# Step 4: Retrieve the embedding vectors for context and questions\n",
    "# Assuming `embedding_small_context` and `embedding_small_question` are columns containing the precomputed embeddings\n",
    "context_embeddings = np.vstack(df[\"embedding_context\"].values)  # Context embeddings\n",
    "question_embeddings = np.vstack(df[\"embedding_question\"].values)  # Question embeddings\n",
    "\n",
    "# Step 5: Combine TF-IDF and embeddings for context and questions\n",
    "# Directly concatenate the TF-IDF vectors and embeddings\n",
    "context_combined = np.hstack([context_tfidf.toarray(), context_embeddings])\n",
    "question_combined = np.hstack([question_tfidf.toarray(), question_embeddings])\n",
    "\n",
    "# Step 6: Compute cosine similarity (Lexical + Embedding similarity)\n",
    "combined_similarity_matrix = cosine_similarity(question_combined, context_combined)\n",
    "\n",
    "# Step 7: Function to compute recall@K for combined lexical and embedding search\n",
    "def compute_recall_at_k_combined(similarity_matrix, k):\n",
    "    num_questions = similarity_matrix.shape[0]\n",
    "    correct_matches = 0\n",
    "\n",
    "    for i in range(num_questions):\n",
    "        # Get indices of top K most similar contexts for question i\n",
    "        top_k_indices = np.argsort(similarity_matrix[i])[::-1][:k]\n",
    "\n",
    "        # Check if the correct context is in the top K\n",
    "        if i in top_k_indices:\n",
    "            correct_matches += 1\n",
    "\n",
    "    recall_at_k = correct_matches / num_questions\n",
    "    return recall_at_k\n",
    "\n",
    "# Step 8: Evaluate Recall@K for combined lexical and embedding search (for different values of k)\n",
    "k_values = [1, 3, 5, 10, 20, 40]\n",
    "combined_recall_scores = {f\"Recall@{k}\": compute_recall_at_k_combined(combined_similarity_matrix, k) for k in k_values}\n",
    "\n",
    "# Step 9: Print combined recall scores\n",
    "print(\"Combined Lexical + Embedding Search Recall Scores:\", combined_recall_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Recall@1': 0.2128463476070529,\n",
       " 'Recall@3': 0.3677581863979849,\n",
       " 'Recall@5': 0.44584382871536526,\n",
       " 'Recall@10': 0.5516372795969773,\n",
       " 'Recall@20': 0.6492443324937027,\n",
       " 'Recall@40': 0.75}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Recall@1': 0.24181360201511334,\n",
       " 'Recall@3': 0.3973551637279597,\n",
       " 'Recall@5': 0.47858942065491183,\n",
       " 'Recall@10': 0.5976070528967254,\n",
       " 'Recall@20': 0.7052896725440806,\n",
       " 'Recall@40': 0.8047858942065491}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_recall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Recall@1': 0.28463476070528965,\n",
       " 'Recall@3': 0.464735516372796,\n",
       " 'Recall@5': 0.5434508816120907,\n",
       " 'Recall@10': 0.6511335012594458,\n",
       " 'Recall@20': 0.7651133501259446,\n",
       " 'Recall@40': 0.8589420654911839}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_recall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall@1</th>\n",
       "      <th>Recall@3</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Recall@20</th>\n",
       "      <th>Recall@40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OpenAI Large Embeddings</th>\n",
       "      <td>0.212846</td>\n",
       "      <td>0.367758</td>\n",
       "      <td>0.445844</td>\n",
       "      <td>0.551637</td>\n",
       "      <td>0.649244</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.241814</td>\n",
       "      <td>0.397355</td>\n",
       "      <td>0.478589</td>\n",
       "      <td>0.597607</td>\n",
       "      <td>0.705290</td>\n",
       "      <td>0.804786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hybrid</th>\n",
       "      <td>0.284635</td>\n",
       "      <td>0.464736</td>\n",
       "      <td>0.543451</td>\n",
       "      <td>0.651134</td>\n",
       "      <td>0.765113</td>\n",
       "      <td>0.858942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Recall@1  Recall@3  Recall@5  Recall@10  Recall@20  \\\n",
       "OpenAI Large Embeddings  0.212846  0.367758  0.445844   0.551637   0.649244   \n",
       "TF-IDF                   0.241814  0.397355  0.478589   0.597607   0.705290   \n",
       "Hybrid                   0.284635  0.464736  0.543451   0.651134   0.765113   \n",
       "\n",
       "                         Recall@40  \n",
       "OpenAI Large Embeddings   0.750000  \n",
       "TF-IDF                    0.804786  \n",
       "Hybrid                    0.858942  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_resutls = pd.DataFrame([recall_scores, lexical_recall_scores, combined_recall_scores])\n",
    "final_resutls.index = [\"OpenAI Large Embeddings\", \"TF-IDF\", \"Hybrid\"]\n",
    "final_resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_resutls.to_excel(\"answers.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped by Organization, then taking average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Only Search\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to compute recall@K\n",
    "def compute_recall_at_k(similarity_matrix, k):\n",
    "    num_questions = similarity_matrix.shape[0]\n",
    "    correct_matches = 0\n",
    "    \n",
    "    for i in range(num_questions):\n",
    "        # Get indices of top K most similar context embeddings for question i\n",
    "        top_k_indices = np.argsort(similarity_matrix[i])[::-1][:k]  # Sort in descending order\n",
    "        \n",
    "        # Check if the correct context (same row in DataFrame) is in the top K\n",
    "        if i in top_k_indices:\n",
    "            correct_matches += 1\n",
    "\n",
    "    recall_at_k = correct_matches / num_questions\n",
    "    return recall_at_k\n",
    "\n",
    "# Define k values\n",
    "k_values = [1, 3, 5, 10, 20, 40]\n",
    "\n",
    "# Dictionary to store recall scores for each abbreviation\n",
    "recall_scores_list = []\n",
    "\n",
    "# Group by \"Abbreviation\" and compute recall scores separately\n",
    "for abbreviation, group in df_combined.groupby(\"Abbreviation\"):\n",
    "    # Convert embedding columns to NumPy arrays\n",
    "    context_embeddings = np.vstack(group[\"embedding_context\"].values)   # Shape: (num_contexts, embedding_dim)\n",
    "    question_embeddings = np.vstack(group[\"embedding_question\"].values) # Shape: (num_questions, embedding_dim)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_matrix = cosine_similarity(question_embeddings, context_embeddings)\n",
    "\n",
    "    # Compute recall@K for the group\n",
    "    recall_scores = {f\"Recall@{k}\": compute_recall_at_k(similarity_matrix, k) for k in k_values}\n",
    "    recall_scores[\"Abbreviation\"] = abbreviation  # Store abbreviation\n",
    "\n",
    "    # Append to list\n",
    "    recall_scores_list.append(recall_scores)\n",
    "\n",
    "# Convert list of scores to DataFrame\n",
    "recall_scores_df = pd.DataFrame(recall_scores_list)\n",
    "\n",
    "# Compute the average recall scores across abbreviations\n",
    "average_recall_scores_embedding = recall_scores_df.drop(columns=[\"Abbreviation\"]).mean().to_dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF only. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to compute recall@K for lexical search\n",
    "def compute_recall_at_k_lexical(similarity_matrix, k):\n",
    "    num_questions = similarity_matrix.shape[0]\n",
    "    correct_matches = 0\n",
    "\n",
    "    for i in range(num_questions):\n",
    "        # Get indices of top K most similar contexts for question i\n",
    "        top_k_indices = np.argsort(similarity_matrix[i])[::-1][:k]\n",
    "\n",
    "        # Check if the correct context is in the top K\n",
    "        if i in top_k_indices:\n",
    "            correct_matches += 1\n",
    "\n",
    "    recall_at_k = correct_matches / num_questions\n",
    "    return recall_at_k\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df_combined[\"Context\"].tolist())\n",
    "\n",
    "# Define k values\n",
    "k_values = [1, 3, 5, 10, 20, 40]\n",
    "\n",
    "# Dictionary to store recall scores for each abbreviation\n",
    "recall_scores_list = []\n",
    "\n",
    "# Group by \"Abbreviation\" and compute recall scores separately\n",
    "for abbreviation, group in df_combined.groupby(\"Abbreviation\"):\n",
    "    # Initialize the TF-IDF Vectorizer and fit only on the contexts within the group\n",
    "    \n",
    "\n",
    "    # Transform contexts and questions within the group\n",
    "    context_tfidf = vectorizer.transform(group[\"Context\"].tolist())\n",
    "    question_tfidf = vectorizer.transform(group[\"Question\"].tolist())\n",
    "\n",
    "    # Compute cosine similarity (Lexical similarity between questions and contexts)\n",
    "    lexical_similarity_matrix = cosine_similarity(question_tfidf, context_tfidf)\n",
    "\n",
    "    # Compute recall@K for lexical search in this group\n",
    "    recall_scores = {f\"Recall@{k}\": compute_recall_at_k_lexical(lexical_similarity_matrix, k) for k in k_values}\n",
    "    recall_scores[\"Abbreviation\"] = abbreviation  # Store abbreviation\n",
    "\n",
    "    # Append to list\n",
    "    recall_scores_list.append(recall_scores)\n",
    "\n",
    "# Convert list of scores to DataFrame\n",
    "recall_scores_df = pd.DataFrame(recall_scores_list)\n",
    "\n",
    "# Compute the average recall scores across abbreviations\n",
    "average_recall_scores_tfidf = recall_scores_df.drop(columns=[\"Abbreviation\"]).mean().to_dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid Search\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to compute recall@K\n",
    "def compute_recall_at_k_combined(similarity_matrix, k):\n",
    "    num_questions = similarity_matrix.shape[0]\n",
    "    correct_matches = 0\n",
    "\n",
    "    for i in range(num_questions):\n",
    "        top_k_indices = np.argsort(similarity_matrix[i])[::-1][:k]\n",
    "        if i in top_k_indices:\n",
    "            correct_matches += 1\n",
    "\n",
    "    return correct_matches / num_questions\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df_combined[\"Context\"].tolist())\n",
    "\n",
    "# Define k values\n",
    "k_values = [1, 3, 5, 10, 20, 40]\n",
    "\n",
    "# Dictionary to store recall scores for each abbreviation\n",
    "recall_scores_list = []\n",
    "\n",
    "# Group by \"Abbreviation\" and compute recall scores separately\n",
    "for abbreviation, group in df_combined.groupby(\"Abbreviation\"):\n",
    "    # Initialize TF-IDF Vectorizer and fit on contexts within the group\n",
    "\n",
    "    # Transform contexts and questions within the group\n",
    "    context_tfidf = vectorizer.transform(group[\"Context\"].tolist())\n",
    "    question_tfidf = vectorizer.transform(group[\"Question\"].tolist())\n",
    "\n",
    "    # Retrieve embeddings\n",
    "    context_embeddings = np.vstack(group[\"embedding_context\"].values)\n",
    "    question_embeddings = np.vstack(group[\"embedding_question\"].values)\n",
    "\n",
    "    # Combine TF-IDF and embeddings\n",
    "    context_combined = np.hstack([context_tfidf.toarray(), context_embeddings])\n",
    "    question_combined = np.hstack([question_tfidf.toarray(), question_embeddings])\n",
    "\n",
    "    # Compute similarity matrix\n",
    "    similarity_matrix = cosine_similarity(question_combined, context_combined)\n",
    "\n",
    "    # Compute recall@K for the group\n",
    "    recall_scores = {f\"Recall@{k}\": compute_recall_at_k_combined(similarity_matrix, k) for k in k_values}\n",
    "    recall_scores[\"Abbreviation\"] = abbreviation  # Store abbreviation\n",
    "\n",
    "    # Append to list\n",
    "    recall_scores_list.append(recall_scores)\n",
    "\n",
    "# Convert list of scores to DataFrame\n",
    "recall_scores_df = pd.DataFrame(recall_scores_list)\n",
    "\n",
    "# Compute the average recall scores across abbreviations\n",
    "average_recall_scores_hybrid = recall_scores_df.drop(columns=[\"Abbreviation\"]).mean().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_resutls = pd.DataFrame([average_recall_scores_embedding, average_recall_scores_tfidf, average_recall_scores_hybrid])\n",
    "average_resutls.index = [\"OpenAI Large Embeddings\", \"TF-IDF\", \"Hybrid\"]\n",
    "average_resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomoro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
